{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from sqlalchemy import create_engine, Table, Column, Integer, String, MetaData, select, Float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|██████████| 6.30M/6.30M [00:00<00:00, 13.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Configurando Dados do driver do navegador utilizado para raspagem de dados (Google Chrome).\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.implicitly_wait(3)\n",
    "driver.get('https://www.fundsexplorer.com.br/ranking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundsTable = WebDriverWait(driver, 5).until(\n",
    "    EC.presence_of_element_located(\n",
    "        (By.CSS_SELECTOR, '[data-element=\"table-ranking-container\"]')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for row in fundsTable.find_elements(By.TAG_NAME, 'tr'):\n",
    "    registers = [register.text for register in row.find_elements(By.TAG_NAME, 'td')]\n",
    "\n",
    "    if registers:\n",
    "        data.append(registers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando DataFrame com os dados raspados.\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data,\n",
    "    columns=[\n",
    "        'Code', \n",
    "        'Sector', \n",
    "        'Current Price', \n",
    "        'Daily Liquidity', \n",
    "        'P-VP', \n",
    "        'Last Dividend',\n",
    "        'Dividend Yield', \n",
    "        'DY Accumulated (3M)', \n",
    "        'DY Accumulated (6M)', \n",
    "        'DY Accumulated (12M)',\n",
    "        'DY Average (3M)', \n",
    "        'DY Average (6M)', \n",
    "        'DY Average (12M)', \n",
    "        'DY Year', \n",
    "        'Price Variation',    \n",
    "        'R Period', \n",
    "        'R Accumulated', \n",
    "        'Net worth', \n",
    "        'VPA', \n",
    "        'P-VPA',    \n",
    "        'DY Equity', \n",
    "        'Equity Variation', \n",
    "        'RP Period', \n",
    "        'RP Accumulated',    \n",
    "        'Physical Vacancy', \n",
    "        'Financial Vacancy', \n",
    "        'Q Active'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo os dados para o tipo correto:\n",
    "for column in df.columns:\n",
    "    df[column] = df[column].apply(lambda item: pd.NA if (item == 'N/A') else item)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratando dados capturados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- # Descarte de Registros Duplicados.\n",
    "- - # Principais motivos para o descarte de dados duplicados:\n",
    "\n",
    "- - - Precisão: Dados duplicados podem levar a uma supervalorização da importância de um determinado valor ou observação.\n",
    "- - - Eficiência: Quando há muitos dados duplicados, a manipulação desses dados tende a se torna mais lenta e a consumir mais recursos computacionais do que o necessário.\n",
    "- - - Consistência: Dados duplicados podem levar a inconsistências nos resultados finais e diminui a garantia que as informações estejam corretas e coerentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedData = df.drop_duplicates(keep=False).copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- # Descarte de Atributos Definidos Como Irrelevantes.\n",
    "- - # Atributos Descartados:\n",
    "\n",
    "- - - (DY Accumulated (3M)): Devido ao fato de ser um atributo que não será utilizado.\n",
    "- - - (DY Accumulated (6M)): Devido ao fato de ser um atributo que não será utilizado.\n",
    "- - - (DY Accumulated (12M)): Devido ao fato de ser um atributo que não será utilizado.\n",
    "- - - (DY Average (3M)): Devido ao fato de ser um atributo que não será utilizado.\n",
    "- - - (DY Average (6M)): Devido ao fato de ser um atributo que não será utilizado.\n",
    "- - - (DY Average (12M)): Devido ao fato de ser um atributo que não será utilizado.\n",
    "- - - (R Period): Devido ao fato de ser um atributo que não será utilizado.\n",
    "- - - (R Accumulated): Devido ao fato de ser um atributo que não será utilizado.\n",
    "- - - (VPA): Devido ao fato de ser um atributo que não será utilizado.\n",
    "- - - (P-VPA): Devido ao fato de ser um atributo que não será utilizado.\n",
    "- - - (DY Equity): Devido ao fato de ser um atributo que não será utilizado.\n",
    "- - - (RP Period): Devido ao fato de ser um atributo que não será utilizado.\n",
    "- - - (RP Accumulated): Devido ao fato de ser um atributo que não será utilizado.\n",
    "- - - (Net worth): Devido ao fato de ser um atributo que não será utilizado.\n",
    "- - - (Physical Vacancy): Devido ao fato de que mais de 60% do seus registros estão nulos, optamos pelo descarte do atributo.\n",
    "- - - (Financial Vacancy): Devido ao fato de que mais de 90% do seus registros estão nulos, optamos pelo descarte do atributo.\n",
    "- - - (Q Active): Devido ao fato de ser um atributo que não será utilizado.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- Devido ao fato de que alguns valores estão vazios ou não são uteis para o processamento, decidimos pelo descarte dos mesmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descartando atributos irrelevantes:\n",
    "processedData.drop(\n",
    "    [\n",
    "        'DY Accumulated (3M)',\n",
    "        'DY Accumulated (6M)',\n",
    "        'DY Accumulated (12M)',\n",
    "        'DY Average (3M)',\n",
    "        'DY Average (6M)',\n",
    "        'DY Average (12M)',\n",
    "        'R Period',\n",
    "        'R Accumulated',\n",
    "        'VPA',\n",
    "        'P-VPA',\n",
    "        'DY Equity',\n",
    "        'RP Period',\n",
    "        'RP Accumulated',\n",
    "        'Net worth',\n",
    "        'Physical Vacancy',\n",
    "        'Financial Vacancy',\n",
    "        'Q Active',\n",
    "    ],\n",
    "    inplace=True,\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- # Convertendo Registros de Atributos.\n",
    "\n",
    "- - # Atributos Convertidos Para Float:\n",
    "- - - (Current Price)\n",
    "- - - (Daily Liquidity)\n",
    "- - - (Last Dividend)\n",
    "- - - (Dividend Yield)\n",
    "- - - (DY Year)\n",
    "- - - (Price Variation)\n",
    "- - - (P-VP)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- Devido ao fato de que os valores foram retirados da internet, a sua maioria encontra-se no formato de String/Objeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo Registros de Dados Para Tipo (Float).\n",
    "\n",
    "for column in processedData.columns[2:]:\n",
    "    processedData[column] = processedData[column].apply(\n",
    "        lambda item: item\n",
    "        if pd.isna(item) or isinstance(item, float)\n",
    "        else float(\n",
    "            item.replace('R$ ', '').replace('%', '').replace('.', '').replace(',', '.')\n",
    "        )\n",
    "        if isinstance(item, str)\n",
    "        else item\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- # Preenchimento de Dados Ausentes.\n",
    "\n",
    "- - # Atributos Categóricos:\n",
    "- - - Para os atributos categóricos que se encontram vazios sera utilizado o termo '`INDEFINIDO`'.\n",
    "- - - Utilizamos o termo '`INDEFINIDO`' apenas como um informe de que o registro do campo não foi informado. \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- - # Atributos Quantitativos:\n",
    "- - - Para os atributos quantitativos que se encontram vazios sera utilizado a `mediana` da coluna do atributo atual.\n",
    "- - - Utilizamos a `mediana` para manter a distribuição original do atributo, assim ele não terá sua a forma de distribuição alterada.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- Todos os atributos iram passar pelo prenchimento para garantir que não existam valores vazios no DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituindo Valores de Dados Ausentes.\n",
    "\n",
    "# Trantando Dados Categóricos.\n",
    "for column in processedData.columns[:2]:\n",
    "    processedData[column].fillna(\"INDEFINIDO\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituindo Valores de Dados Ausentes.\n",
    "\n",
    "# Trantando Dados Quantitativos.\n",
    "for column in processedData.columns[2:]:\n",
    "    processedData[column].fillna(processedData[column].median(), inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- # Identificando e Tratando Atributos com Registros Outliers.\n",
    "- - # Desvio Padrão:\n",
    "- - - Será utilizado o método do `Desvio Padrão` para análise de `outliers`: Esse método identifica outliers como valores que estão a uma distancia maior que 3 vezes o desvio padrão da media.\n",
    "- - - Optamos pelo uso do `Desvio Padrão` por ser um dos metodos mais comuns e eficientes para esse tipo de base de dados.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- - # Substituição Dos Valores Discrepantes Pelo Valor da Mediana do Atributo.\n",
    "- - O método utilizado para o tratamento de outliers é o de `Substituição Dos Valores Discrepantes Pelo Valor da Mediana do Atributo`.\n",
    "- - Utilizamos esse método póis ao substituir os valores outliers pela mediana, a distribuição dos dados é menos afetada pelos valores extremos, preservando assim a estrutura da distribuição original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituindo Registros Discrepantes dos Dados.\n",
    "\n",
    "# Percorrendo Registros Quantitativos.\n",
    "for column in processedData.columns[2:]:\n",
    "    median = processedData[column].median()\n",
    "\n",
    "    q1 = processedData[column].quantile(0.25)\n",
    "    q3 = processedData[column].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "\n",
    "    processedData[column] = processedData[column].apply(\n",
    "        lambda item: 0.0 if item < lower else median if item > upper else item\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando os dados no banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///../database.db', echo=False)\n",
    "metadata = MetaData()\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundsTable = Table(\n",
    "    'Funds',\n",
    "    MetaData(),\n",
    "    Column('id', Integer, primary_key=True, autoincrement=True),\n",
    "    Column('Code', String(50)),\n",
    "    Column('Sector', String(50)),\n",
    "    Column('Current Price', Float),\n",
    "    Column('Daily Liquidity', Float),\n",
    "    Column('P-VP', Float),\n",
    "    Column('Last Dividend', Float),\n",
    "    Column('Dividend Yield', Float),\n",
    "    Column('DY Year', Float),\n",
    "    Column('Price Variation', Float),\n",
    "    Column('Equity Variation', Float),\n",
    ")\n",
    "\n",
    "metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processedData['id'] = processedData.reset_index().index + 1\n",
    "\n",
    "processedData.to_sql('Funds', conn, if_exists='replace', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
